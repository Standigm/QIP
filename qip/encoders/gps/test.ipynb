{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/db2/users/jungwookim/anaconda3/envs/grpe/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /db2/users/jungwookim/anaconda3/envs/grpe/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from admet_prediction.datamodules.featurizers import OGBFeaturizer\n",
    "from admet_prediction.datamodules.transforms import RandomWalkGenerator\n",
    "from admet_prediction.encoders.gps.encoders import NodeEncoder, EdgeEncoder\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "featurizer = OGBFeaturizer()\n",
    "rw = RandomWalkGenerator(\n",
    "    ksteps=[1,17],\n",
    "    space_dim=0\n",
    ")\n",
    "node = NodeEncoder(\n",
    "    dim_in=1,\n",
    "    dim_posenc=20,\n",
    "    dim_emb=384,\n",
    "    ksteps=[1,17],\n",
    "    expand_x=False,\n",
    "    batch_norm=False,\n",
    ")\n",
    "edge = EdgeEncoder(\n",
    "    dim_emb=384,\n",
    "    batch_norm=False\n",
    ")\n",
    "\n",
    "\n",
    "smi = 'c1ccc(CCC)c(CC)c1'\n",
    "data = featurizer(smi)\n",
    "data = rw(data)\n",
    "\n",
    "#data.x = node(data.x, data.rwse)\n",
    "#data.edge_attr = edge(data.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from admet_prediction.encoders.gps.gnn import GNNEncoder\n",
    "import torch\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = GNNEncoder(\n",
    "    model='gatv2',\n",
    "    d_model=128,\n",
    "    nhead=8,\n",
    "    dropout=0.1,\n",
    "    layer_norm=False,\n",
    "    num_layer=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_state = copy.deepcopy(encoder.state_dict())\n",
    "optimizer = torch.optim.SGD(encoder.parameters(), lr=0.1)\n",
    "STEPS = 10\n",
    "# check unused parameters\n",
    "for _ in range(STEPS):\n",
    "    optimizer.zero_grad()\n",
    "    output = encoder(x=data.x, edge_index=data.edge_index, edge_attr=data.edge_attr, batch=data.batch)\n",
    "    (output[0]**2).sum().backward()  # dummy loss\n",
    "    optimizer.step()\n",
    "after_state = encoder.state_dict()\n",
    "unused_param_names = []\n",
    "used_params = []\n",
    "for state_key in before_state.keys():\n",
    "    if (before_state[state_key] == after_state[state_key]).all():\n",
    "        # params which is not updated during training\n",
    "        unused_param_names.append(state_key)\n",
    "    else:\n",
    "        used_params.append(state_key)\n",
    "assert len(unused_param_names) == 0, f\"Unused parameters: {unused_param_names}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNEncoder(\n",
      "  (atom): AtomEncoder(\n",
      "    (atom_embedding_list): ModuleList(\n",
      "      (0): Embedding(119, 128)\n",
      "      (1): Embedding(19, 128)\n",
      "      (2): Embedding(7, 128)\n",
      "      (3): Embedding(5, 128)\n",
      "      (4-5): 2 x Embedding(12, 128)\n",
      "      (6): Embedding(10, 128)\n",
      "      (7-8): 2 x Embedding(6, 128)\n",
      "      (9-10): 2 x Embedding(3, 128)\n",
      "    )\n",
      "  )\n",
      "  (bond): EdgeEncoder(\n",
      "    (encoder): BondEncoder(\n",
      "      (bond_embedding_list): ModuleList(\n",
      "        (0): Embedding(5, 128)\n",
      "        (1): Embedding(7, 128)\n",
      "        (2): Embedding(3, 128)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (model): GATv2(128, 128, num_layers=2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atom.atom_embedding_list.0.weight', 'atom.atom_embedding_list.1.weight', 'atom.atom_embedding_list.2.weight', 'atom.atom_embedding_list.3.weight', 'atom.atom_embedding_list.4.weight', 'atom.atom_embedding_list.5.weight', 'atom.atom_embedding_list.6.weight', 'atom.atom_embedding_list.7.weight', 'atom.atom_embedding_list.8.weight', 'atom.atom_embedding_list.9.weight', 'atom.atom_embedding_list.10.weight', 'bond.encoder.bond_embedding_list.0.weight', 'bond.encoder.bond_embedding_list.1.weight', 'bond.encoder.bond_embedding_list.2.weight', 'model.convs.0.att', 'model.convs.0.bias', 'model.convs.0.lin_l.weight', 'model.convs.0.lin_l.bias', 'model.convs.0.lin_r.weight', 'model.convs.0.lin_r.bias', 'model.convs.0.lin_edge.weight', 'model.convs.1.att', 'model.convs.1.bias', 'model.convs.1.lin_l.weight', 'model.convs.1.lin_l.bias', 'model.convs.1.lin_r.weight', 'model.convs.1.lin_r.bias', 'model.convs.1.lin_edge.weight', 'model.norms.0.weight', 'model.norms.0.bias']\n"
     ]
    }
   ],
   "source": [
    "print(used_params1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atom.atom_embedding_list.0.weight', 'atom.atom_embedding_list.1.weight', 'atom.atom_embedding_list.2.weight', 'atom.atom_embedding_list.3.weight', 'atom.atom_embedding_list.4.weight', 'atom.atom_embedding_list.5.weight', 'atom.atom_embedding_list.6.weight', 'atom.atom_embedding_list.7.weight', 'atom.atom_embedding_list.8.weight', 'atom.atom_embedding_list.9.weight', 'atom.atom_embedding_list.10.weight', 'bond.encoder.bond_embedding_list.0.weight', 'bond.encoder.bond_embedding_list.1.weight', 'bond.encoder.bond_embedding_list.2.weight', 'model.convs.0.att', 'model.convs.0.bias', 'model.convs.0.lin_l.weight', 'model.convs.0.lin_l.bias', 'model.convs.0.lin_r.weight', 'model.convs.0.lin_r.bias', 'model.convs.0.lin_edge.weight', 'model.convs.1.att', 'model.convs.1.bias', 'model.convs.1.lin_l.weight', 'model.convs.1.lin_l.bias', 'model.convs.1.lin_r.weight', 'model.convs.1.lin_r.bias', 'model.convs.1.lin_edge.weight']\n"
     ]
    }
   ],
   "source": [
    "print(used_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.norms.0.bias', 'model.norms.0.weight'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(used_params1).difference(set(used_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from admet_prediction.encoders.gps.gnn import GATv2\n",
    "import torch.nn as nn\n",
    "\n",
    "d_model = 128\n",
    "nhead=8\n",
    "dropout=0.1\n",
    "num_layer=2\n",
    "gat = GATv2(\n",
    "    in_channels = d_model,\n",
    "    hidden_channels = d_model,\n",
    "    heads = nhead,\n",
    "    dropout = dropout,\n",
    "    num_layers = num_layer,\n",
    "    act = nn.SiLU(),\n",
    "    norm = 'batchnorm',\n",
    "    edge_dim = d_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i, param in gat.named_parameters():\n",
    "    \n",
    "    if i == 'norms.0.module.weight':\n",
    "        print(param)\n",
    "    elif i=='norms.0.module.bias':\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "['MessageNorm', 'HeteroBatchNorm', 'GraphNorm', 'BatchNorm', 'LayerNorm', \n",
    "'HeteroLayerNorm', 'GraphSizeNorm', 'DiffGroupNorm', 'MeanSubtractionNorm', \n",
    "'PairNorm', 'InstanceNorm']\n",
    "d_model=32\n",
    "gat = GATv2(\n",
    "    in_channels = d_model,\n",
    "    hidden_channels = d_model,\n",
    "    heads = nhead,\n",
    "    dropout = dropout,\n",
    "    num_layers = num_layer,\n",
    "    act = nn.SiLU(),\n",
    "    norm = 'LayerNorm',\n",
    "    edge_dim = d_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for i, param in gat.named_parameters():\n",
    "    if i.split('.')[0] == 'norms':\n",
    "        print(param)\n",
    "\n",
    "        a.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "'MessageNorm', 'HeteroBatchNorm', 'GraphNorm', 'BatchNorm', 'LayerNorm', \n",
    "'HeteroLayerNorm', 'GraphSizeNorm', 'DiffGroupNorm', 'MeanSubtractionNorm', \n",
    "'PairNorm', 'InstanceNorm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch_geometric.nn.norm.batch_norm.BatchNorm,\n",
       " torch_geometric.nn.norm.batch_norm.HeteroBatchNorm,\n",
       " torch_geometric.nn.norm.instance_norm.InstanceNorm,\n",
       " torch_geometric.nn.norm.layer_norm.LayerNorm,\n",
       " torch_geometric.nn.norm.layer_norm.HeteroLayerNorm,\n",
       " torch_geometric.nn.norm.graph_norm.GraphNorm,\n",
       " torch_geometric.nn.norm.graph_size_norm.GraphSizeNorm,\n",
       " torch_geometric.nn.norm.pair_norm.PairNorm,\n",
       " torch_geometric.nn.norm.mean_subtraction_norm.MeanSubtractionNorm,\n",
       " torch_geometric.nn.norm.msg_norm.MessageNorm,\n",
       " torch_geometric.nn.norm.diff_group_norm.DiffGroupNorm]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convs.0.att\n",
      "convs.0.bias\n",
      "convs.0.lin_l.weight\n",
      "convs.0.lin_l.bias\n",
      "convs.0.lin_r.weight\n",
      "convs.0.lin_r.bias\n",
      "convs.0.lin_edge.weight\n",
      "convs.1.att\n",
      "convs.1.bias\n",
      "convs.1.lin_l.weight\n",
      "convs.1.lin_l.bias\n",
      "convs.1.lin_r.weight\n",
      "convs.1.lin_r.bias\n",
      "convs.1.lin_edge.weight\n",
      "norms.0.weight\n",
      "norms.0.bias\n"
     ]
    }
   ],
   "source": [
    "for i, param in gat.named_parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gps",
   "language": "python",
   "name": "gps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ece373c48b535c2c07e954e4c144e7b0b81e34ca5c7491755299787960820bf9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
