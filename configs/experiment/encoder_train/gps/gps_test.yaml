# @package _global_

defaults:
  - /system: encoder_train.yaml
  # override
  # system config
  - /system/encoder_config: "gps/default.yaml"
  - /system/task_head_configs: gps/gps_test_task.yaml
  - /system/optimizer_configs: null
  # train config
  - override /trainer:
      [
        "default",
        "accelerator/gpu",
        "devices/4-2",
        "max_steps/10k",
        "strategy/ddp",
        "accumulate_grad_batches/8",
        "precision/16"
      ]
  - override /callbacks: default.yaml
  - override /datamodule: "gps/gps_test.yaml"
  - override /logger: ["csv", "wandb", "mlflow"]

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters
trainer:
  #strategy: ddp_find_unused_parameters_true
  val_check_interval: 8
datamodule:
  batch_size: 8
name: gps_test
seed: 8282
system:
#   checkpoint_path: null
#   trainable_modules: null
#   freeze_modules: null

  # encoder_config:
  #   module:
  #     use_independent_token: True
  #   state_path: /db2/users/jungwookim/projects/admet_prediction/outputs/train/runs/encoder_train/grpe/default/P2/scratch_indep/2023-05-04/19-39-54/checkpoints/checkpoint_000153711/encoder.pt

  #task_head_configs:
    # CYP: Classification
    # cyp-1a2:
    #   weight: 0.05
    # cyp-2c9:
    #   weight: 0.075

    # cyp-2c19:
    #   weight: 0.075
    # cyp-2d6:
    #   weight: 0.05
    # cyp-3a4:
    #   weight: 0.05
    # # hERG : Classification
    # herg:
    #   weight: 0.15
    # # lipophilicity : Regression
    # lipophilicity:
    #   weight: 0.15
    # # MS : Classification
    # ms-human:
    #   weight: 0.15
    # ms-mouse:
    #   weight: 0.15
    # # permeability : Classification
    # permeability:
    #   weight: 0.15
    # # solubility_pbs : Classification
    # solubility-pbs:
    #   weight: 0.15
    # # nabladft : Regression

  optimizer_configs:
    - optimizer:
        _target_: torch.optim.AdamW
        lr: 5e-7 # use very small lr with CosineAnnealingWarmUpRestartsWithDecay
        # params: null # null or '' for all parameters
        # modules: null # null or '' for all module parameters
      lr_scheduler:
        scheduler:
          _target_: admet_prediction.modules.lr_scheduler.CosineAnnealingWarmUpRestartsWithDecay
          T_0: 10_000
          T_mult: null
          eta_max: 1e-6
          T_up: 0
          gamma: 1.0
        interval: "step"
        frequency: 1